#!/usr/bin/env python3
"""
Telemetry UI (Pygame-CE)

Shows:
- Arena image with checkpoints path; highlights current segment.
- Estimated current pose on the arena during movement.
- Live sensors: lidar, IMU (accel/gyro/heading/temp), rotation, staleness.

Assumptions & notes:
- Loads arena.png and checkpoints_cm.csv (generated by measure_arena.py).
- Loads path.csv (turn_deg, distance_cm) to know segment plan.
- Auto phase tracking: uses advanced.get_rotation_degrees() and lidar deltas
  to infer whether the bot is turning or moving and which segment is active.
- Starting position is first checkpoint; initial heading assumed arbitrary,
  first turn is relative to current facing (controller resets gyro).

Controls:
- R: reload path/checkpoints
- A: toggle auto phase tracking on/off (manual index)
- [ / ]: manual current segment index -/+ (when auto off)
- Esc/Q: quit
"""
import os
import csv
import math
import time
import pygame as pg

from advanced import (
    init_bot_control, cleanup,
    get_rotation_degrees, get_full_imu_data,
    is_lidar_data_fresh, get_current_distance
)


ARENA_WIDTH_CM = 118.0
ARENA_HEIGHT_CM = 114.0


def load_image(path: str) -> pg.Surface:
    img = pg.image.load(path)
    return img


def compute_px_cm(img_w, img_h):
    px_per_cm_x = img_w / ARENA_WIDTH_CM
    px_per_cm_y = img_h / ARENA_HEIGHT_CM
    return px_per_cm_x, px_per_cm_y


def fit_scale_and_offset(win_size, img_size):
    ww, wh = win_size
    iw, ih = img_size
    s = min(ww / iw, wh / ih) if iw and ih else 1.0
    ox = (ww - iw * s) / 2
    oy = (wh - ih * s) / 2
    return s, (ox, oy)


def image_to_screen(pt, scale, offset):
    x, y = pt
    ox, oy = offset
    return (ox + x * scale, oy + y * scale)


def cm_to_image_xy(x_cm, y_cm, px_per_cm_x, px_per_cm_y):
    return (x_cm * px_per_cm_x, y_cm * px_per_cm_y)


def heading_from_up_deg(vx_cm, vy_cm):
    if abs(vx_cm) < 1e-9 and abs(vy_cm) < 1e-9:
        return 0.0
    return math.degrees(math.atan2(vx_cm, -vy_cm)) % 360.0


def wrap_to_180(deg):
    d = (deg + 180.0) % 360.0 - 180.0
    if d <= -180.0:
        d += 360.0
    return d


def load_path(script_dir):
    path_csv = os.path.join(script_dir, "path.csv")
    segs = []  # list of (turn_deg, dist_cm)
    if os.path.exists(path_csv):
        with open(path_csv, newline="") as f:
            reader = csv.DictReader(f)
            for row in reader:
                try:
                    turn = float(row.get("turn_deg", "0"))
                    dist = float(row.get("distance_cm", "0"))
                    segs.append((turn, dist))
                except Exception:
                    pass
    return segs


def load_checkpoints(script_dir):
    pts_csv = os.path.join(script_dir, "checkpoints_cm.csv")
    pts = []
    if os.path.exists(pts_csv):
        with open(pts_csv, newline="") as f:
            reader = csv.DictReader(f)
            for row in reader:
                try:
                    x = float(row.get("x_cm", "0"))
                    y = float(row.get("y_cm", "0"))
                    pts.append((x, y))
                except Exception:
                    pass
    return pts


def draw_text(surface, text, pos, font, color=(240, 240, 240)):
    img = font.render(text, True, color)
    surface.blit(img, pos)


def main():
    pg.init()
    pg.display.set_caption("Telemetry UI")

    script_dir = os.path.dirname(__file__)
    arena_path = os.path.join(script_dir, "arena.png")
    if not os.path.exists(arena_path):
        raise FileNotFoundError("arena.png not found next to telemetry_ui.py")
    arena_img = load_image(arena_path)
    iw, ih = arena_img.get_width(), arena_img.get_height()
    px_per_cm_x, px_per_cm_y = compute_px_cm(iw, ih)

    # Window arrangement: make it resizable
    info = pg.display.Info()
    w, h = int(info.current_w * 0.9), int(info.current_h * 0.9)
    screen = pg.display.set_mode((w, h), pg.RESIZABLE)
    font = pg.font.SysFont(None, 18)
    font_big = pg.font.SysFont(None, 24)

    # Load plan and checkpoints
    segments = load_path(script_dir)
    checkpoints = load_checkpoints(script_dir)

    # Telemetry init
    init_bot_control(verbose_telemetry=False)

    # Phase tracking
    auto_track = True
    seg_idx = 0
    phase = "idle"  # "turn", "move"
    ROT_TOL = 5.0  # degrees
    DIST_TOL = 3.0  # cm
    move_start_lidar_mm = None
    move_target_cm = 0.0
    seg_heading = None

    # Live pose (in cm); initialize at first checkpoint if available
    live_x_cm = checkpoints[0][0] if checkpoints else 0.0
    live_y_cm = checkpoints[0][1] if checkpoints else 0.0
    live_heading_deg = 0.0  # 0° = up; we use gyro-integrated rotation as heading

    clock = pg.time.Clock()
    running = True
    while running:
        ww, wh = screen.get_size()
        scale, offset = fit_scale_and_offset((ww, wh), (iw, ih))

        for e in pg.event.get():
            if e.type == pg.QUIT:
                running = False
            elif e.type == pg.KEYDOWN:
                if e.key in (pg.K_ESCAPE, pg.K_q):
                    running = False
                elif e.key == pg.K_r:
                    segments = load_path(script_dir)
                    checkpoints = load_checkpoints(script_dir)
                    seg_idx = 0
                    phase = "idle"
                    move_start_lidar_mm = None
                    # Reset live pose to first checkpoint
                    if checkpoints:
                        live_x_cm, live_y_cm = checkpoints[0]
                    else:
                        live_x_cm, live_y_cm = 0.0, 0.0
                    live_heading_deg = 0.0
                elif e.key == pg.K_a:
                    auto_track = not auto_track
                elif e.key == pg.K_LEFTBRACKET and not auto_track:
                    seg_idx = max(0, seg_idx - 1)
                    phase = "idle"
                elif e.key == pg.K_RIGHTBRACKET and not auto_track:
                    seg_idx = min(max(0, len(segments) - 1), seg_idx + 1)
                    phase = "idle"

        # Telemetry snapshot
        imu = get_full_imu_data()
        rotation_deg = get_rotation_degrees()
        lidar_mm = get_current_distance()
        lidar_fresh = is_lidar_data_fresh(max_age_seconds=1.0)

        # Update live heading from gyro-derived rotation (wrap to [0,360))
        live_heading_deg = (rotation_deg % 360.0 + 360.0) % 360.0

        # Auto phase estimation
        if auto_track and segments:
            if seg_idx >= len(segments):
                phase = "done"
            else:
                turn_deg, dist_cm = segments[seg_idx]
                if phase in ("idle", "turn"):
                    # Expect the robot to turn towards turn_deg (relative turn)
                    phase = "turn"
                    # Detect completion of turn by rotation within tolerance
                    if abs(rotation_deg - turn_deg) <= ROT_TOL:
                        phase = "move"
                        move_start_lidar_mm = lidar_mm
                        move_target_cm = dist_cm
                        # Compute expected absolute segment heading: previous seg headings accumulate
                        # For visualization, derive from plan: accumulate turns
                        # But for simplicity, compute seg heading relative to up using plan increments
                        # We'll approximate by summing relative turns from start (0° at up)
                        seg_heading = sum(t for (t, _) in segments[:seg_idx+1]) % 360.0
                elif phase == "move":
                    # Estimate traveled using lidar delta in cm
                    if move_start_lidar_mm is not None and lidar_fresh:
                        traveled_cm = (lidar_mm - move_start_lidar_mm) / 10.0
                        # Finish segment when close to target
                        if abs(move_target_cm - traveled_cm) <= DIST_TOL:
                            seg_idx += 1
                            phase = "idle"
                            move_start_lidar_mm = None

        # Draw arena and overlays
        screen.fill((15, 18, 22))
        if abs(scale - 1.0) < 1e-6:
            screen.blit(arena_img, offset)
        else:
            scaled = pg.transform.smoothscale(arena_img, (int(iw * scale), int(ih * scale)))
            screen.blit(scaled, offset)

        # Draw path (from checkpoints)
        # Convert checkpoints (cm) -> image px -> screen
        pts_img = [cm_to_image_xy(x, y, px_per_cm_x, px_per_cm_y) for (x, y) in checkpoints]
        pts_scr = [image_to_screen(p, scale, offset) for p in pts_img]
        # Segments coloring
        for i in range(1, len(pts_scr)):
            a = pts_scr[i - 1]
            b = pts_scr[i]
            if i - 1 < seg_idx:
                color = (100, 200, 100)  # done
            elif i - 1 == seg_idx:
                color = (0, 220, 255)    # current
            else:
                color = (120, 120, 120)  # pending
            pg.draw.line(screen, color, a, b, 3)
            pg.draw.circle(screen, color, (int(a[0]), int(a[1])), 4)
        if pts_scr:
            pg.draw.circle(screen, (200, 200, 200), (int(pts_scr[-1][0]), int(pts_scr[-1][1])), 4)

        # Estimated robot pose on current segment (simple progress along segment)
        if segments and checkpoints and 0 <= seg_idx < len(segments) and len(checkpoints) >= 2:
            # Compute progress ratio during move phase
            ratio = 0.0
            if phase == "move" and move_start_lidar_mm is not None and lidar_fresh:
                traveled_cm = (lidar_mm - move_start_lidar_mm) / 10.0
                if abs(move_target_cm) > 1e-3:
                    ratio = max(0.0, min(1.0, traveled_cm / move_target_cm))
            # Current segment endpoints in cm
            i0 = seg_idx
            if i0 + 1 < len(checkpoints):
                p0 = checkpoints[i0]
                p1 = checkpoints[i0 + 1]
                x = p0[0] + (p1[0] - p0[0]) * ratio
                y = p0[1] + (p1[1] - p0[1]) * ratio
                # Persist live pose in cm
                live_x_cm, live_y_cm = x, y
                # Draw robot marker
                rx_img, ry_img = cm_to_image_xy(x, y, px_per_cm_x, px_per_cm_y)
                rx, ry = image_to_screen((rx_img, ry_img), scale, offset)
                pg.draw.circle(screen, (255, 80, 80), (int(rx), int(ry)), 6)
                # Draw orientation arrow (use accumulated planned heading if available)
                heading = seg_heading if seg_heading is not None else live_heading_deg
                rad = math.radians(heading)
                # 0° up => vector (0, -1); we map to screen delta using img px/cm relationship roughly
                vx = math.sin(rad) * 20
                vy = -math.cos(rad) * 20
                pg.draw.line(screen, (255, 80, 80), (rx, ry), (rx + vx, ry + vy), 3)
        else:
            # If we can't compute from segments, still draw live pose at last known location
            rx_img, ry_img = cm_to_image_xy(live_x_cm, live_y_cm, px_per_cm_x, px_per_cm_y)
            rx, ry = image_to_screen((rx_img, ry_img), scale, offset)
            pg.draw.circle(screen, (255, 80, 80), (int(rx), int(ry)), 6)
            rad = math.radians(live_heading_deg)
            vx = math.sin(rad) * 20
            vy = -math.cos(rad) * 20
            pg.draw.line(screen, (255, 80, 80), (rx, ry), (rx + vx, ry + vy), 3)

        # Right side HUD panel (transparent overlay)
        hud = pg.Surface((int(ww * 0.34), wh), pg.SRCALPHA)
        hud.fill((0, 0, 0, 140))
        screen.blit(hud, (ww - hud.get_width(), 0))
        hud_x = ww - hud.get_width() + 12
        y = 10
        draw_text(screen, "Telemetry UI", (hud_x, y), font_big)
        y += 28
        draw_text(screen, f"Segments: {len(segments)}  Index: {seg_idx}  Phase: {phase}", (hud_x, y), font)
        y += 22
        # IMU
        draw_text(screen, "IMU:", (hud_x, y), font_big)
        y += 22
        accel = imu.get('accel', {})
        gyro = imu.get('gyro', {})
        heading = imu.get('heading', 0.0)
        temp_c = imu.get('temp_c', 0.0)
        draw_text(screen, f"Accel: x={accel.get('x',0):.2f} y={accel.get('y',0):.2f} z={accel.get('z',0):.2f}", (hud_x, y), font)
        y += 18
        draw_text(screen, f"Gyro:  x={gyro.get('x',0):.2f} y={gyro.get('y',0):.2f} z={gyro.get('z',0):.2f}", (hud_x, y), font)
        y += 18
        draw_text(screen, f"Heading(abs): {heading:.1f}°  Rot(rel): {rotation_deg:.1f}°", (hud_x, y), font)
        y += 18
        draw_text(screen, f"Temp: {temp_c:.1f}°C", (hud_x, y), font)
        y += 24

        # Lidar
        draw_text(screen, "LIDAR:", (hud_x, y), font_big)
        y += 22
        st = "OK" if lidar_fresh else "STALE"
        draw_text(screen, f"Distance: {lidar_mm} mm  [{st}]", (hud_x, y), font)
        y += 24

        # Live Pose
        draw_text(screen, "Pose:", (hud_x, y), font_big)
        y += 22
        draw_text(screen, f"x={live_x_cm:.1f} cm  y={live_y_cm:.1f} cm  heading={live_heading_deg:.1f}°", (hud_x, y), font)
        y += 24

        # Encoders (placeholder)
        draw_text(screen, "Encoders:", (hud_x, y), font_big)
        y += 22
        draw_text(screen, "(not connected)", (hud_x, y), font)
        y += 24

        # Controls
        draw_text(screen, "Controls:", (hud_x, y), font_big)
        y += 22
        draw_text(screen, "R: reload plan   A: auto track on/off   [/]: manual seg", (hud_x, y), font)
        y += 18
        draw_text(screen, "Esc/Q: quit", (hud_x, y), font)

        pg.display.flip()
        clock.tick(60)

    cleanup()
    pg.quit()


if __name__ == "__main__":
    main()
